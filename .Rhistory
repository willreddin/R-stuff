#set WD
setwd("~/Documents/R/Housing-association-data")
#get all the urls for HAs from this page: "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
indexUrl <- "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
#set html to the url for individual HA record
html <- htmlTreeParse(indexUrl, useInternalNodes=T)
#use xpath to get all of the links for each HA record
links <- xpathSApply(html, "//p//a", xmlGetAttr, "href")
#loop through each link, and return the data table for each HA
parsePage <- function(links) {
#create empty data.frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
#write values to a data frame and transpose to a row
v <- t(data.frame(values))
#set colnames for table to be the headings
v <- colnames(v) <- headings
#bind the title to a column
v <- cbind(title, v)
d <- rbind(d, v)
}
lapply(links, parsePage)
write.csv(d, file= "housing-association-data.csv", na="NA")
parsePage(lins[1])
parsePage(links[1])
this <- parsePage(links[1])
View(this)
d <- data.frame()
links <- links[1]
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
headings
values
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
title
v <- t(data.frame(values))
View(v)
v <- colnames(v) <- headings
View(v)
colnames(v) <- headings
v <- t(data.frame(values))
View(v)
colnames(v) <- headings
View(v)
v <- cbind(title, v)
View(v)
d <- rbind(d, v)
View(d)
parsePage <- function(links) {
#create empty data frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
#write values to a data frame and transpose to a row
v <- t(data.frame(values))
#set colnames for table to be the headings
colnames(v) <- headings
#bind the title to a column
v <- cbind(title, v)
#bind the row to the empty data frame
d <- rbind(d, v)
}
parsePage(links[3])
parsePage(links[4])
parsePage(links[1])
parsePage(links[2])
parsePage(links[5])
parsePage(links[6])
this <- parsePage(links[1])
View(this)
d <- data.frame()
this <- t(data.frame(values))
this <- colnames(this) <- headings
this <- cbind(title, this)
library(XML)
#set WD
setwd("~/Documents/R/Housing-association-data")
#get all the urls for HAs from this page: "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
indexUrl <- "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
#set html to the url for individual HA record
html <- htmlTreeParse(indexUrl, useInternalNodes=T)
#use xpath to get all of the links for each HA record
links <- xpathSApply(html, "//p//a", xmlGetAttr, "href")
#loop through each link, and return the data table for each HA
parsePage <- function(links) {
#create empty data frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
#write values to a data frame and transpose to a row
v <- t(data.frame(values))
#set colnames for table to be the headings
colnames(v) <- headings
#bind the title to a column
v <- cbind(title, v)
#bind the row to the empty data frame
d <- rbind(d, v)
}
finalData <- lapply(links, parsePage)
write.csv(finalData, file= "housing-association-data.csv", na="NA")
links
lapply(links[1:3], parsePage)
d <- data.frame()
this <- t(data.frame(values))
this <- colnames(this) <- headings
this <- cbind(title, this)
library(XML)
#set WD
setwd("~/Documents/R/Housing-association-data")
#get all the urls for HAs from this page: "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
indexUrl <- "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
#set html to the url for individual HA record
html <- htmlTreeParse(indexUrl, useInternalNodes=T)
#use xpath to get all of the links for each HA record
links <- xpathSApply(html, "//p//a", xmlGetAttr, "href")
#loop through each link, and return the data table for each HA
parsePage <- function(links) {
#create empty data frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
#write values to a data frame and transpose to a row
v <- t(data.frame(values))
#set colnames for table to be the headings
colnames(v) <- headings
#bind the title to a column
v <- cbind(title, v)
#bind the row to the empty data frame
d <- rbind.fill(d, v)
}
finalData <- lapply(links, parsePage)
write.csv(finalData, file= "housing-association-data.csv", na="NA")
is.data.frame(v)
d <- data.frame()
this <- t(data.frame(values))
this <- colnames(this) <- headings
this <- cbind(title, this)
library(XML)
#set WD
setwd("~/Documents/R/Housing-association-data")
#get all the urls for HAs from this page: "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
indexUrl <- "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
#set html to the url for individual HA record
html <- htmlTreeParse(indexUrl, useInternalNodes=T)
#use xpath to get all of the links for each HA record
links <- xpathSApply(html, "//p//a", xmlGetAttr, "href")
#loop through each link, and return the data table for each HA
parsePage <- function(links) {
#create empty data frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
#write values to a data frame and transpose to a row
v <- t(data.frame(values))
V <- data.frame(v)
#set colnames for table to be the headings
colnames(v) <- headings
#bind the title to a column
v <- cbind(title, v)
#bind the row to the empty data frame
d <- rbind.fill(d, v)
}
finalData <- lapply(links, parsePage)
write.csv(finalData, file= "housing-association-data.csv", na="NA")
is.data.frame(v)
d <- data.frame()
this <- t(data.frame(values))
this <- colnames(this) <- headings
this <- cbind(title, this)
library(XML)
#set WD
setwd("~/Documents/R/Housing-association-data")
#get all the urls for HAs from this page: "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
indexUrl <- "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
#set html to the url for individual HA record
html <- htmlTreeParse(indexUrl, useInternalNodes=T)
#use xpath to get all of the links for each HA record
links <- xpathSApply(html, "//p//a", xmlGetAttr, "href")
#loop through each link, and return the data table for each HA
parsePage <- function(links) {
#create empty data frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
#write values to a data frame and transpose to a row
v <- t(data.frame(values))
v <- data.frame(v)
#set colnames for table to be the headings
colnames(v) <- headings
#bind the title to a column
v <- cbind(title, v)
#bind the row to the empty data frame
d <- rbind.fill(d, v)
}
finalData <- lapply(links, parsePage)
write.csv(finalData, file= "housing-association-data.csv", na="NA")
View(v)
is.data.frame(v)
data.frame(v)
v<- data.frame(v)
is.data.frame(v)
links <- links[1]
#create empty data frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
values
headings
title
v <- t(data.frame(values))
is.data.frame(v)
t(values)
View(t(values))
v <- data.frame(t(values))
is.data.frame(v)
colnames(v) <- headings
v <- cbind(title, v)
d <- rbind.fill(d, v)
View(d)
is.data.frame(d)
d <- data.frame()
this <- t(data.frame(values))
this <- colnames(this) <- headings
this <- cbind(title, this)
library(XML)
#set WD
setwd("~/Documents/R/Housing-association-data")
#get all the urls for HAs from this page: "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
indexUrl <- "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
#set html to the url for individual HA record
html <- htmlTreeParse(indexUrl, useInternalNodes=T)
#use xpath to get all of the links for each HA record
links <- xpathSApply(html, "//p//a", xmlGetAttr, "href")
#loop through each link, and return the data table for each HA
parsePage <- function(links) {
#create empty data frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
#write values to a data frame and transpose to a row
v <- data.frame(t(values))
#set colnames for table to be the headings
colnames(v) <- headings
#bind the title to a column
v <- cbind(title, v)
#bind the row to the empty data frame
d <- rbind.fill(d, v)
}
finalData <- lapply(links, parsePage)
write.csv(finalData, file= "housing-association-data.csv", na="NA")
colnames.fill?
z
?colnames.fill
d <- data.frame()
this <- t(data.frame(values))
this <- colnames(this) <- headings
this <- cbind(title, this)
library(XML)
#set WD
setwd("~/Documents/R/Housing-association-data")
#get all the urls for HAs from this page: "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
indexUrl <- "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
#set html to the url for individual HA record
html <- htmlTreeParse(indexUrl, useInternalNodes=T)
#use xpath to get all of the links for each HA record
links <- xpathSApply(html, "//p//a", xmlGetAttr, "href")
#loop through each link, and return the data table for each HA
parsePage <- function(links) {
#create empty data frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
#write values to a data frame and transpose to a row
v <- data.frame(t(values))
#set colnames for table to be the headings
colnames(v) <- headings
#bind the title to a column
v <- cbind(title, v)
#bind the row to the empty data frame
d <- rbind.fill(d, v)
#write table to file with url as name
write.csv(d, file= paste(title, ".csv", sep=""), na="NA")
}
finalData <- lapply(links, parsePage)
d <- data.frame()
this <- t(data.frame(values))
this <- colnames(this) <- headings
this <- cbind(title, this)
library(XML)
#set WD
setwd("~/Documents/R/Housing-association-data")
#get all the urls for HAs from this page: "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
indexUrl <- "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
#set html to the url for individual HA record
html <- htmlTreeParse(indexUrl, useInternalNodes=T)
#use xpath to get all of the links for each HA record
links <- xpathSApply(html, "//p//a", xmlGetAttr, "href")
#loop through each link, and return the data table for each HA
parsePage <- function(links) {
#create empty data frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
#write values to a data frame and transpose to a row
v <- data.frame(t(values))
#set colnames for table to be the headings
colnames(v) <- headings
#bind the title to a column
v <- cbind(title, v)
#bind the row to the empty data frame
d <- rbind.fill(d, v)
#write table to file with url as name
write.csv(d, file= paste(title, ".csv", sep=""), na="NA")
}
lapply(links, parsePage)
parsePage(links[1])
read.csv("A2Dominion Group.csv")
d <- data.frame()
this <- t(data.frame(values))
this <- colnames(this) <- headings
this <- cbind(title, this)
library(XML)
#set WD
setwd("~/Documents/R/Housing-association-data")
#get all the urls for HAs from this page: "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
indexUrl <- "http://www.theguardian.com/housing-network/2012/jun/08/housing-association-profiles"
#set html to the url for individual HA record
html <- htmlTreeParse(indexUrl, useInternalNodes=T)
#use xpath to get all of the links for each HA record
links <- xpathSApply(html, "//p//a", xmlGetAttr, "href")
#loop through each link, and return the data table for each HA
parsePage <- function(links) {
#create empty data frame for later
d <- data.frame()
#set html to the url for individual HA record
IndividualHtml <- htmlTreeParse(links, useInternalNodes=T)
#set headings for individual HA page
headings <- xpathSApply(IndividualHtml, "//strong", xmlValue)
#get the non strong values
values <- xpathSApply(IndividualHtml, "//strong/following-sibling::text()[1]", xmlValue)
#parse the title of the housing association from the page
title <- gsub("\n", "",  xpathSApply(IndividualHtml, "//h1[1]", xmlValue))
#write values to a data frame and transpose to a row
v <- data.frame(t(values))
#set colnames for table to be the headings
#colnames(v) <- headings
#bind the title to a column
v <- cbind(title, v)
#bind the row to the empty data frame
d <- rbind.fill(d, v)
#write table to file with url as name
write.csv(d, file= paste(title, ".csv", sep=""), na="NA")
}
lapply(links, parsePage)
read.csv("Futures Housing.csv")
View(read.csv("Futures Housing.csv"))
links
lapply(links[45:124], parsePage)
file_list <- list.files()
file_list
file_list <- list.files()
for (file in file_list){
# if the merged dataset doesn't exist, create it
if (!exists("dataset")){
dataset <- read.table(file, header=TRUE, sep="\t")
}
# if the merged dataset does exist, append to it
if (exists("dataset")){
temp_dataset <-read.table(file, header=TRUE, sep="\t")
dataset<-rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
file_list <- list.files()
for (file in file_list){
# if the merged dataset doesn't exist, create it
if (!exists("dataset")){
dataset <- read.table(file, header=TRUE, sep=",")
}
# if the merged dataset does exist, append to it
if (exists("dataset")){
temp_dataset <-read.table(file, header=TRUE, sep=",")
dataset<-rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
file_list <- list.files()
for (file in file_list){
# if the merged dataset doesn't exist, create it
if (!exists("dataset")){
dataset <- read.table(file, header=TRUE, sep=",")
}
# if the merged dataset does exist, append to it
if (exists("dataset")){
temp_dataset <-read.table(file, header=TRUE, sep=",")
dataset<-rbind.fill(dataset, temp_dataset)
rm(temp_dataset)
}
}
View(dataset)
drops <- c("X.title.X1.X2.X3.X4.X5.X6.X7.X8", "X")
datasetRef <- dataset[,!(names(DF) %in% drops)]
datasetRef <- dataset[,!(names(dataset) %in% drops)]
View(datasetRef)
dataset <- datasetRef
View(dataset)
dataset[-c(1,2), ]
datasetTing <- dataset[-c(1,2), ]
View(datasetTing)
dataset <- datasetTing
drops <- c("row.names")
datasetRef <- dataset[,!(names(dataset) %in% drops)]
View(datasetRef)
drops
rownames(dataset) <- NULL
dataset
View(dataset)
?write.csv
write.csv(dataset, file="housing-association-merged-data")
getwd()
setwd("/Users/will/Documents/R)
setwd("/Users/will/Documents/R)
x
setwd("/Users/will/Documents/R")
write.csv(dataset, file="housing-association-merged-data")
colnames(dataset) <- c("Name", "Established", "Location", "Stock", "Turnover", "Staff", "Areas of work", "Chief Exec", "Exec 2", "Exec 3")
View(dataset)
getwd()
write.csv(dataset, file="housing-association-merged-data")
View(read.csv("housing-association-merged-data"))
?sort
view(dataset)
View(dataset)
View(order(dataset, "Turnover" )
x
View(dataset[order(Turnover), ])
View(dataset[order("Turnover"), ])
Turnover <- dataset[order("Turnover")]
View(Turnover)
Turnover <- dataset[order("Turnover"),]
View(Turnover)
Turnover <- dataset[order(Turnover),]
View(Turnover)
Stock <- dataset[order(Stock),]
Stock <- dataset[order("Stock"),]
View(Stock)
t <- dataset[order(Stock),]
View(t)
t <- dataset[order(4),]
View(t)
